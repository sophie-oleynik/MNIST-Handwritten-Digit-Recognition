# MNIST-Handwritten-Digit-Recognition

### 1. Набiр даних
  Для навчання було використано 44736 зображень, для перевiрки 14913 зображення , для тестування 10351. Було виконано нормалізацiю даних, шляхом дiлення значення пiкселя на 255. 255 тому, що це максимальне значення. Зображення поданi у форматi 28х28 пiкселiв. В данiй лабораторнiй роботi фiчами є значення пiкселiв поданi у форматi вiд 0 до 255. При цьому слiд пам’ятати, що при аналiзi зображення також є важливим значення сусiднiх пiкселiв.
  
### 2. Структура моделi
  Модель побудавано викиристовуючи Sequential iз бiблiотеки keras. Для початку у моедль додається шар Conv2D, що створює ядро згортки(convolution kernel) розмiром 3х3. Далi шар пулiнгу MaxPooling2D, що обирає найбiльше значення iз розрностi 2х2(4 пiкселя). Далi iде шар Flatten, що перетворює 2-вирний масив для роботи з ним у повнiстю зв’язаних шарах(fully connected layers). Далi iде шар звичайний Dense шар розмiру 150. Потiм шар Dropout для недопущення перенавчання(overfitting). I останнiй шар Dense розмiру 10, так як у нас 10 цифр.
  
### 3. Результати експериментiв
  Для моделi був обраний розмiр batch=32 так як експерементально вiн дав найбiльшу точнiсть. Швидкiсть навчання стандартна для оптимiзатора Адам з бiблiотеки Keras - 0.001, так як вона давала найкращу точнiсть. Перехресна перевiрка не виконувалась. Основною метрикою є точнiсть(accuracy), що розраховується за формулою count/total.
  
### 4.  Висновки
  У данiй лабораторнiй роботi було розроблено нейронну мережу, що розпiзнає цифри. Найкращi результати показала модель описана у роздiлi "Структура моделi". Збiльшення швидкостi навчання призводило до зниження точностi через "розхитування"моделi. Архiтектура мережi є досить простою та стандартною для вирiшення такого простого класу задач. Тобто спочатку сonvulation layer, а далi pooling i flattening. А далi вже шари Dense та Dropout. Найбiльшу точнiсть показав оптимiзатор Адам.

